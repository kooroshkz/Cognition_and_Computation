{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eeaeec-0eaf-40da-a2c6-73b311f34840",
   "metadata": {},
   "source": [
    "# Evidence accumulation models\n",
    "In this assignment, we simulate a simple *evidence accumulation model* from scratch. The following papers gives a general introduction to how evidence accumulation models (sometimes called 'sequential sampling models') are used:\n",
    "\n",
    "- Forstmann, B. U., Ratcliff, R., & Wagenmakers, E.-J. (2016). Sequential Sampling Models in Cognitive Neuroscience: Advantages, Applications, and Extensions. Annual Review of Psychology, 67(1), 641–666. https://doi.org/10.1146/annurev-psych-122414-033645\n",
    "\n",
    "The model we will simulate is described by Bogacz et al. (2006), p. 704, section 'DDM':\n",
    "\n",
    "- Bogacz, R., Brown, E., Moehlis, J., Holmes, P., & Cohen, J. D. (2006). The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks. Psychological Review, 113(4), 700–765. https://doi.org/10.1037/0033-295X.113.4.700\n",
    "\n",
    "\n",
    "The model was originally proposed in (this is only intended as background literature, not required for this assigment):\n",
    "- Stone, M. (1960). Models for choice-reaction time. Psychometrika, 25(3), 251–260. https://doi.org/10.1007/BF02289729\n",
    "- Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60886f39-e9ab-4a34-a2ca-bd95792e97cc",
   "metadata": {},
   "source": [
    "Evidence accumulation models are formalized theories of decision making, often used to analyse data from two-alternative forced choice decision-making tasks. In this tasks, participants are presented with a stimulus, and are required to make a decision based on that stimulus. For example, the stimulus could be a Gabor patch tilted to the left or to the right:\n",
    "<figure><img src=\"https://jspsychophysics.hes.kyushu-u.ac.jp/images/gabor.png\"></figure>\n",
    "\n",
    "and the participants need to respond 'left' or 'right'. Or the stimulus could be a [random-dot kinetogram](https://www.youtube.com/watch?v=7OdCe95IiLw), and the participants need to respond whether the cloud of dots moves to the left or to the right.\n",
    "\n",
    "\n",
    "Evidence accumulation models assume that people make decisions by gradually accumulating evidence for each choice option while watching the stimulus. Evidence accumulation proceeds until a threshold level of evidence is reached. At that point, the decision corresponding to the threshold (sometimes called 'decision bound') is made. This is often visualized as follows:\n",
    "\n",
    "<figure><img src='https://surfdrive.surf.nl/files/index.php/s/3ESvM7R9a5bs1LU/download'> </figure>\n",
    "\n",
    "where the thresholds are indicated by the blue horizontal lines in the middle panel. The top threshold could indicate a choice for 'choose left', and the bottom threshold for 'choose right'. The gray line traces the evidence accumulation over time. In this example, evidence accumulation reaches the top threshold, and a choice for 'left' is made. If the stimulus indeed required a left answer, then this choice was correct.\n",
    "\n",
    "By repeating this process over and over again across many trials, gradually, response time distributions arise:\n",
    "\n",
    "<figure><img src='https://surfdrive.surf.nl/files/index.php/s/6pOmJXvpZzx4EDd/download'> </figure>\n",
    "\n",
    "#### Structure of this assignment\n",
    "In this assignment, we will gradually build up an evidence accumulation model in three steps:\n",
    "\n",
    "1. We start by simulating a random walk;\n",
    "2. We then end the random walk whenever a threshold is reached;\n",
    "3. Then, we add a drift to the random walk\n",
    "\n",
    "With this model, we then explore how the parameters are related to empirical data.\n",
    "\n",
    "That covers the basics of an evidence accumulation model. With that simple model, we can simulate decision times, choices, and the effects of changing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6fbe7a-d4b0-471e-ba1f-7991353387dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd6f2b0-1c45-4e24-b521-d14600759aaf",
   "metadata": {},
   "source": [
    "## Part 1. Simulate a random walk\n",
    "\n",
    "A random walk is characterized by the differential equation:\n",
    "\n",
    "$dx/dt = cdW$\n",
    "\n",
    "i.e., any change in $x$ during time step $dt$ is Gaussian noise $dW$ with variance $c* dt$. So essentially, at every time step, we just add normally distributed noise to $x$.\n",
    "\n",
    "Another way of describing the this process is the recursive equation:\n",
    "\n",
    "$x_{i+1} = x_{i} + cdW$ \n",
    "\n",
    "\n",
    "### Assignment 1.1\n",
    "To simulate a random walk process, initiate variable `x` at 0. Then, create a `for`-loop with 5000 iterations. Every iteration of the `for`-loop approximates `dt` seconds, i.e., when we set `dt = 0.001`, we simulate with a 1 millisecond time resolution, and in total we simulate 5 seconds (5000 times 1 millisecond)\n",
    "\n",
    "In every iteration of the `for`-loop, do the following:\n",
    " - increase `x` with Gaussian noise with standard deviation $\\sqrt{c* dt}$ to `x`, where `c = 1` and `dt = 0.001`\n",
    " - save the state of `x` to a vector called `xs`\n",
    "\n",
    "After all iterations, the vector `xs` should contain the full random walk over time.\n",
    "\n",
    "(NB: the numpy function for random Gaussian noise requests the standard deviation, not the variance, so you need to calculate the standard deviation before passing it to the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d5973c-ee8e-4136-b66f-26463361417f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)  # don't remove this -- this makes sure the random noise is the same every time you call this function\n",
    "\n",
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65900974-850e-4b69-982d-a01c098b692e",
   "metadata": {},
   "source": [
    "#### Assignment 1.2\n",
    "After the loop, plot `xs` to visualize the random walk across time. If you implement it correctly, it should look like this:      <figure>\n",
    "      <img src=\"https://surfdrive.surf.nl/files/index.php/s/FFKigsGcHTiInUl/download\" alt=\"Random walk\" style=\"width:400pt\">\n",
    "      </figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9454f3f-cded-4e9d-a5df-f207dc68e71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ff33f-1d60-4387-a96e-351d2bfa660f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2. Stop the random walk when it reaches a threshold\n",
    "\n",
    "Assume that evidence accumulation continues until `x` reaches either `+a` or `-a`. At that point, the random walk has reached a decision. The decision time is the number of iterations required to reach the threshold (keeping in mind the time resolution: so 1000 iterations corresponds to $1000 \\times dt = 1000 \\times 0.001 = 1 $ second )\n",
    "\n",
    "#### Assignment 2.1\n",
    "Set `a = 0.5` and simulate the for loop until `a` is reached (with maximally 5000 iterations). What was the decision time? And which choice was made (i.e., the upper bound of `+a` or the lower bound of `-a`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2fa5d8-a421-4832-9b0e-e4fd05992bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30d7f3-1dda-4348-8c7d-aa6e239966dc",
   "metadata": {},
   "source": [
    "#### Assignment 2.2. Wrap your code in a function\n",
    "Create a new function called `simulate_single_trial`. It takes as arguments: `a`, `c`, `dt`, and `max_time_steps`. In the function, the for loop is executed. The function returns the decision time, the choice, and `xs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c2dc7b-9128-4aed-8081-66f6496ef8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e962a-6c47-4f49-81c1-e0c362d26c26",
   "metadata": {},
   "source": [
    "The function provides a conventient way to simulate multiple trials.\n",
    "\n",
    "#### Assignment 2.3\n",
    "Simulate 500 trials. After every trial, save the decision time and the choice.\n",
    "What is the mean decision time across the 500 trials? And what was the error rate (the proportion of trials reaching the *lower* bound?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcb79be-3f84-4ddb-9777-93bdef08b941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf3cb7-1c2a-455e-80fb-fcf243034116",
   "metadata": {},
   "source": [
    "#### Assignment 2.4\n",
    "Plot the [histogram](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) of decision times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb80de82-3eeb-4816-9bdd-fad168d1c4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef2419-9ce4-4e33-b11d-d0591e80e4af",
   "metadata": {},
   "source": [
    "## Part 3. Add a drift. \n",
    "\n",
    "The differential equation for a random walk with drift is:\n",
    "\n",
    "$dx/dt = vdt + cdW$\n",
    "\n",
    "Where `v` is known as the drift rate.\n",
    "\n",
    "#### Assignment 3.1\n",
    "Implement a drift rate in the `for` loop of your function `simulate_single_trial`. Note that drift rate `v` needs to be scaled (multiplied) by `dt` before adding it to `x`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92b8e7b-691f-4d26-9c93-661312f7eb55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2904ab-8ac0-4034-b6cb-6b9d6a06a0dd",
   "metadata": {},
   "source": [
    "#### Assignment 3.2\n",
    "Again, simulate 500 trials. Use a drift rate of `v=1`. After every trial, store the decision time and the choice. What is the mean decision time across trials? What was the error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9cafc27-5d5e-4fd0-a2d5-2fe08fc0cd07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725d954-21ca-4e63-86c9-f086fe5f17e4",
   "metadata": {},
   "source": [
    "It's possible to calculate the mean response time and the error rate analytically. Bogacz et al (2006) give the following Equations 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7773a89f-0281-408d-a32d-8c997040730a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ER(v, a, c):\n",
    "    ''' Returns error rate (proportion of errors) given drift rate `v`, threshold `a`, and diffusion noise `c`'''\n",
    "    return 1/(1+np.exp(2*v*a/c**2))\n",
    "    \n",
    "def DT(v, a, c):\n",
    "    ''' Returns mean decision time given drift rate `v`, threshold `a`, and diffusion noise `c`'''\n",
    "    if v == 0:\n",
    "        ### prevent division by 0\n",
    "        v = 0.00000001\n",
    "    return (a/v) * np.tanh((v*a)/(c**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442bbfa-2e67-4231-a5ff-86d52bea031e",
   "metadata": {},
   "source": [
    "#### Assignment 3.3\n",
    "Check whether your simulated mean RT and error rate approximate to the analytical mean RT and error rate. Note that due to simulation noise, small deviations from the analytical values can be expected. The more trials you simulate, the closer the analytical and simulated values should get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b3d699-c1b8-4709-880c-4f91e02a686d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee475e-3d3a-4c2e-b6e9-3c30000a1dd7",
   "metadata": {},
   "source": [
    "## Part 4. The effects of the drift and threshold parameters\n",
    "In this section, we explore what the effect is of increasing/decreasing the drift rate on the simulated data. Similarly, we explore what the effect is of increasing/decreasing the threshold on the simulated data\n",
    "\n",
    "#### Assignment 4.1\n",
    "Simulate one dataset of 500 trials with `v=1` and `a=1`, and another dataset with `v=2` and `a=1`. Compare the mean decision time, the error rate, and the histograms of the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58f2081-5c15-4643-b061-ff19fb668909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525fbd6-9dfd-4065-8f88-21212ad7ab2a",
   "metadata": {},
   "source": [
    "#### Assignment 4.2\n",
    "Simulate one dataset of 500 trials with `v=1` and `a=1`, and another dataset with `v=1` and `a=1.5`. Compare the mean decision time, the error rate, and the histograms of the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b797efba-2a7e-437c-b3dc-ddaffa0ea054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
